{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47XBZWm4T9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0f8d6c-9b5d-450f-e486-66d3d2d35765"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cp  \"/content/drive/MyDrive/dataset.tar.gz\" ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k4lhiraPr4u",
        "outputId": "ce550cb9-aff7-4637-b1b6-d9ca71907bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FQTVeAuNiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6329919d-5c31-4622-a373-0bf06610321b"
      },
      "source": [
        "# untar\n",
        "!tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTzcSoYl4T97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23778f5-72a1-4e7d-ed07-33649b9ba782"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 11, 11, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sparsity(weights_val):\n",
        "  size = 1\n",
        "  n_zeros = np.count_nonzero(weights_val==0)\n",
        "  # print(n_zeros)\n",
        "  for dim in np.shape(weights_val):\n",
        "    size = size * dim\n",
        "  # print(size)\n",
        "  sparsity = n_zeros/size\n",
        "  return n_zeros, size, sparsity"
      ],
      "metadata": {
        "id": "3e5QQ6W3RapR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Nk_MAPqZPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e065d3f4-5f2f-409c-c521-207dafcd081f"
      },
      "source": [
        "# you can use the default hyper-parameters for training, \n",
        "# and val accuracy ~59% after 25 epochs and > 63% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=16, epochs=50, \n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1405/1405 [==============================] - 7s 4ms/step - loss: 1.4657 - accuracy: 0.3451 - val_loss: 1.3077 - val_accuracy: 0.4352\n",
            "Epoch 2/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.2983 - accuracy: 0.4474 - val_loss: 1.2245 - val_accuracy: 0.4796\n",
            "Epoch 3/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.2350 - accuracy: 0.4857 - val_loss: 1.1563 - val_accuracy: 0.5271\n",
            "Epoch 4/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.1810 - accuracy: 0.5161 - val_loss: 1.1192 - val_accuracy: 0.5481\n",
            "Epoch 5/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.1420 - accuracy: 0.5364 - val_loss: 1.0745 - val_accuracy: 0.5731\n",
            "Epoch 6/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.1030 - accuracy: 0.5569 - val_loss: 1.0595 - val_accuracy: 0.5683\n",
            "Epoch 7/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.0677 - accuracy: 0.5747 - val_loss: 1.0305 - val_accuracy: 0.5834\n",
            "Epoch 8/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.0417 - accuracy: 0.5826 - val_loss: 1.0191 - val_accuracy: 0.5865\n",
            "Epoch 9/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.0173 - accuracy: 0.5954 - val_loss: 0.9531 - val_accuracy: 0.6253\n",
            "Epoch 10/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9888 - accuracy: 0.6099 - val_loss: 0.9615 - val_accuracy: 0.6186\n",
            "Epoch 11/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9717 - accuracy: 0.6196 - val_loss: 0.9392 - val_accuracy: 0.6226\n",
            "Epoch 12/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9458 - accuracy: 0.6295 - val_loss: 0.9238 - val_accuracy: 0.6329\n",
            "Epoch 13/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9304 - accuracy: 0.6353 - val_loss: 0.9487 - val_accuracy: 0.6246\n",
            "Epoch 14/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9078 - accuracy: 0.6509 - val_loss: 0.8683 - val_accuracy: 0.6610\n",
            "Epoch 15/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8960 - accuracy: 0.6536 - val_loss: 0.9185 - val_accuracy: 0.6392\n",
            "Epoch 16/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8768 - accuracy: 0.6616 - val_loss: 0.8964 - val_accuracy: 0.6416\n",
            "Epoch 17/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8582 - accuracy: 0.6735 - val_loss: 0.8479 - val_accuracy: 0.6685\n",
            "Epoch 18/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8433 - accuracy: 0.6775 - val_loss: 0.8410 - val_accuracy: 0.6705\n",
            "Epoch 19/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8277 - accuracy: 0.6848 - val_loss: 0.8184 - val_accuracy: 0.6796\n",
            "Epoch 20/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8133 - accuracy: 0.6902 - val_loss: 0.8179 - val_accuracy: 0.6788\n",
            "Epoch 21/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8038 - accuracy: 0.6925 - val_loss: 0.8159 - val_accuracy: 0.6804\n",
            "Epoch 22/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7823 - accuracy: 0.7018 - val_loss: 0.7860 - val_accuracy: 0.6966\n",
            "Epoch 23/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7739 - accuracy: 0.7037 - val_loss: 0.7918 - val_accuracy: 0.6899\n",
            "Epoch 24/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7539 - accuracy: 0.7144 - val_loss: 0.7856 - val_accuracy: 0.6915\n",
            "Epoch 25/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7451 - accuracy: 0.7184 - val_loss: 0.7646 - val_accuracy: 0.7022\n",
            "Epoch 26/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7359 - accuracy: 0.7189 - val_loss: 0.7593 - val_accuracy: 0.7050\n",
            "Epoch 27/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7234 - accuracy: 0.7254 - val_loss: 0.7666 - val_accuracy: 0.7018\n",
            "Epoch 28/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7114 - accuracy: 0.7308 - val_loss: 0.7528 - val_accuracy: 0.7129\n",
            "Epoch 29/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7007 - accuracy: 0.7348 - val_loss: 0.7418 - val_accuracy: 0.7172\n",
            "Epoch 30/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6872 - accuracy: 0.7422 - val_loss: 0.7497 - val_accuracy: 0.7149\n",
            "Epoch 31/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6807 - accuracy: 0.7427 - val_loss: 0.7232 - val_accuracy: 0.7228\n",
            "Epoch 32/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6722 - accuracy: 0.7452 - val_loss: 0.7603 - val_accuracy: 0.6990\n",
            "Epoch 33/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6587 - accuracy: 0.7539 - val_loss: 0.7291 - val_accuracy: 0.7137\n",
            "Epoch 34/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6478 - accuracy: 0.7557 - val_loss: 0.7292 - val_accuracy: 0.7200\n",
            "Epoch 35/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6420 - accuracy: 0.7570 - val_loss: 0.7554 - val_accuracy: 0.7081\n",
            "Epoch 36/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6287 - accuracy: 0.7597 - val_loss: 0.7240 - val_accuracy: 0.7224\n",
            "Epoch 37/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6185 - accuracy: 0.7667 - val_loss: 0.7110 - val_accuracy: 0.7251\n",
            "Epoch 38/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6119 - accuracy: 0.7681 - val_loss: 0.7158 - val_accuracy: 0.7240\n",
            "Epoch 39/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.6065 - accuracy: 0.7728 - val_loss: 0.7358 - val_accuracy: 0.7204\n",
            "Epoch 40/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5921 - accuracy: 0.7766 - val_loss: 0.7260 - val_accuracy: 0.7251\n",
            "Epoch 41/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5875 - accuracy: 0.7798 - val_loss: 0.7128 - val_accuracy: 0.7299\n",
            "Epoch 42/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5749 - accuracy: 0.7863 - val_loss: 0.6993 - val_accuracy: 0.7354\n",
            "Epoch 43/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5683 - accuracy: 0.7896 - val_loss: 0.7343 - val_accuracy: 0.7160\n",
            "Epoch 44/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5647 - accuracy: 0.7877 - val_loss: 0.6878 - val_accuracy: 0.7390\n",
            "Epoch 45/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5548 - accuracy: 0.7936 - val_loss: 0.6939 - val_accuracy: 0.7358\n",
            "Epoch 46/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5491 - accuracy: 0.7970 - val_loss: 0.7231 - val_accuracy: 0.7315\n",
            "Epoch 47/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5362 - accuracy: 0.8004 - val_loss: 0.6855 - val_accuracy: 0.7335\n",
            "Epoch 48/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5315 - accuracy: 0.8033 - val_loss: 0.6997 - val_accuracy: 0.7390\n",
            "Epoch 49/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5212 - accuracy: 0.8079 - val_loss: 0.6809 - val_accuracy: 0.7390\n",
            "Epoch 50/50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.5176 - accuracy: 0.8066 - val_loss: 0.7009 - val_accuracy: 0.7358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-zwkZTiiQS9",
        "outputId": "90b8e4cf-5961-45f7-9ced-6381fdcb6a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.7358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_weights = model.get_weights()"
      ],
      "metadata": {
        "id": "TIh9ZGcOpzuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrain Attempt\n",
        "## Score: 0.8467\n",
        "\n"
      ],
      "metadata": {
        "id": "NCIVGTnIqeIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.set_weights(original_weights)"
      ],
      "metadata": {
        "id": "GE9Zex4ap4vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (300):\n",
        "  if i < 100:\n",
        "    thresh = 0.095\n",
        "  elif i > 99 and i < 150:\n",
        "    thresh = 0.1\n",
        "  elif i > 149 and i < 200:\n",
        "    thresh = 0.13\n",
        "  else:\n",
        "    thresh = 0.15\n",
        "\n",
        "  print(\"Epoch: {}\".format(i + 1))\n",
        "\n",
        "  history = model.fit(train_images, train_labels, batch_size=16, epochs= 1, \n",
        "                    validation_data=(val_images, val_labels))\n",
        "  weights = model.get_weights()\n",
        "\n",
        "  new_weights = np.array(weights)\n",
        "  for val in range (12):\n",
        "    new_weights[val][np.where(np.abs(new_weights[val]) < thresh)] = 0.0 \n",
        "  model.set_weights(new_weights)\n",
        "  final_sparsity = 0\n",
        "  for arr in model.trainable_variables:\n",
        "      final_sparsity += len(tf.where(arr==0.0))\n",
        "  print(\"Sparsity: {}\".format( final_sparsity/592933))\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEx4k3I0iOso",
        "outputId": "a34e88cd-2816-4272-d4eb-79c3a92ef116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.4783 - accuracy: 0.8244 - val_loss: 0.6895 - val_accuracy: 0.7446\n",
            "Sparsity: 0.9298858387035297\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-111-41b056279a25>:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_weights = np.array(weights)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.4223 - accuracy: 0.4125 - val_loss: 1.1138 - val_accuracy: 0.5659\n",
            "Sparsity: 0.9315740564279607\n",
            "Epoch: 3\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.1890 - accuracy: 0.5430 - val_loss: 0.9097 - val_accuracy: 0.6487\n",
            "Sparsity: 0.9339571250040055\n",
            "Epoch: 4\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.0822 - accuracy: 0.5983 - val_loss: 0.8770 - val_accuracy: 0.6602\n",
            "Sparsity: 0.9358814570954898\n",
            "Epoch: 5\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 1.0200 - accuracy: 0.6209 - val_loss: 0.8673 - val_accuracy: 0.6630\n",
            "Sparsity: 0.9373892159822442\n",
            "Epoch: 6\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9847 - accuracy: 0.6323 - val_loss: 0.8554 - val_accuracy: 0.6642\n",
            "Sparsity: 0.9385917127230227\n",
            "Epoch: 7\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9552 - accuracy: 0.6428 - val_loss: 0.8836 - val_accuracy: 0.6535\n",
            "Sparsity: 0.9395091856921439\n",
            "Epoch: 8\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9432 - accuracy: 0.6449 - val_loss: 0.8450 - val_accuracy: 0.6681\n",
            "Sparsity: 0.9403507647575696\n",
            "Epoch: 9\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9281 - accuracy: 0.6505 - val_loss: 0.8259 - val_accuracy: 0.6824\n",
            "Sparsity: 0.9410641674523091\n",
            "Epoch: 10\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9158 - accuracy: 0.6520 - val_loss: 0.8239 - val_accuracy: 0.6824\n",
            "Sparsity: 0.9417286607424448\n",
            "Epoch: 11\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.9042 - accuracy: 0.6578 - val_loss: 0.8796 - val_accuracy: 0.6590\n",
            "Sparsity: 0.9422363066316093\n",
            "Epoch: 12\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8961 - accuracy: 0.6614 - val_loss: 0.8105 - val_accuracy: 0.6863\n",
            "Sparsity: 0.9426613124923052\n",
            "Epoch: 13\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8896 - accuracy: 0.6626 - val_loss: 0.8338 - val_accuracy: 0.6796\n",
            "Sparsity: 0.9431436604135712\n",
            "Epoch: 14\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8814 - accuracy: 0.6653 - val_loss: 0.8459 - val_accuracy: 0.6689\n",
            "Sparsity: 0.9435315625880158\n",
            "Epoch: 15\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8771 - accuracy: 0.6660 - val_loss: 0.8459 - val_accuracy: 0.6689\n",
            "Sparsity: 0.9438823610762093\n",
            "Epoch: 16\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8645 - accuracy: 0.6714 - val_loss: 0.8237 - val_accuracy: 0.6840\n",
            "Sparsity: 0.944199428940538\n",
            "Epoch: 17\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8666 - accuracy: 0.6700 - val_loss: 0.8170 - val_accuracy: 0.6780\n",
            "Sparsity: 0.9444878257745816\n",
            "Epoch: 18\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8606 - accuracy: 0.6727 - val_loss: 0.8089 - val_accuracy: 0.6891\n",
            "Sparsity: 0.944774536077432\n",
            "Epoch: 19\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8542 - accuracy: 0.6752 - val_loss: 0.8259 - val_accuracy: 0.6820\n",
            "Sparsity: 0.9450292022876109\n",
            "Epoch: 20\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8486 - accuracy: 0.6812 - val_loss: 0.8034 - val_accuracy: 0.6883\n",
            "Sparsity: 0.9452265264372197\n",
            "Epoch: 21\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8454 - accuracy: 0.6786 - val_loss: 0.7993 - val_accuracy: 0.6915\n",
            "Sparsity: 0.945462640804273\n",
            "Epoch: 22\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8415 - accuracy: 0.6802 - val_loss: 0.8363 - val_accuracy: 0.6721\n",
            "Sparsity: 0.9456852629217803\n",
            "Epoch: 23\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8378 - accuracy: 0.6824 - val_loss: 0.7967 - val_accuracy: 0.6927\n",
            "Sparsity: 0.9459180042264471\n",
            "Epoch: 24\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8361 - accuracy: 0.6812 - val_loss: 0.7948 - val_accuracy: 0.6954\n",
            "Sparsity: 0.9461052091888965\n",
            "Epoch: 25\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8307 - accuracy: 0.6875 - val_loss: 0.8093 - val_accuracy: 0.6867\n",
            "Sparsity: 0.9462688027146406\n",
            "Epoch: 26\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8303 - accuracy: 0.6899 - val_loss: 0.7991 - val_accuracy: 0.6923\n",
            "Sparsity: 0.9464357693027712\n",
            "Epoch: 27\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8257 - accuracy: 0.6875 - val_loss: 0.8134 - val_accuracy: 0.6832\n",
            "Sparsity: 0.9465892436413558\n",
            "Epoch: 28\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8270 - accuracy: 0.6854 - val_loss: 0.7991 - val_accuracy: 0.6927\n",
            "Sparsity: 0.9467781351349984\n",
            "Epoch: 29\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8282 - accuracy: 0.6852 - val_loss: 0.7921 - val_accuracy: 0.6994\n",
            "Sparsity: 0.9469012519121047\n",
            "Epoch: 30\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8172 - accuracy: 0.6899 - val_loss: 0.7999 - val_accuracy: 0.6931\n",
            "Sparsity: 0.9470479801259164\n",
            "Epoch: 31\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8182 - accuracy: 0.6921 - val_loss: 0.7817 - val_accuracy: 0.7042\n",
            "Sparsity: 0.9471947083397281\n",
            "Epoch: 32\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8148 - accuracy: 0.6920 - val_loss: 0.8125 - val_accuracy: 0.6820\n",
            "Sparsity: 0.9473026463360953\n",
            "Epoch: 33\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8174 - accuracy: 0.6916 - val_loss: 0.7872 - val_accuracy: 0.7022\n",
            "Sparsity: 0.9474358823003611\n",
            "Epoch: 34\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8127 - accuracy: 0.6956 - val_loss: 0.7976 - val_accuracy: 0.6935\n",
            "Sparsity: 0.9475606856086607\n",
            "Epoch: 35\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8066 - accuracy: 0.6939 - val_loss: 0.7916 - val_accuracy: 0.6986\n",
            "Sparsity: 0.9476854889169603\n",
            "Epoch: 36\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7995 - accuracy: 0.6958 - val_loss: 0.8051 - val_accuracy: 0.6915\n",
            "Sparsity: 0.9477799346637815\n",
            "Epoch: 37\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8047 - accuracy: 0.6929 - val_loss: 0.7692 - val_accuracy: 0.7050\n",
            "Sparsity: 0.9479047379720812\n",
            "Epoch: 38\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8052 - accuracy: 0.6967 - val_loss: 0.7655 - val_accuracy: 0.7050\n",
            "Sparsity: 0.9479840049381634\n",
            "Epoch: 39\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.8024 - accuracy: 0.6947 - val_loss: 0.7779 - val_accuracy: 0.7053\n",
            "Sparsity: 0.9481155543712358\n",
            "Epoch: 40\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7963 - accuracy: 0.7010 - val_loss: 0.7933 - val_accuracy: 0.6923\n",
            "Sparsity: 0.9482201193052167\n",
            "Epoch: 41\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7984 - accuracy: 0.6983 - val_loss: 0.7828 - val_accuracy: 0.6958\n",
            "Sparsity: 0.9483179381144244\n",
            "Epoch: 42\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7908 - accuracy: 0.7035 - val_loss: 0.7659 - val_accuracy: 0.7065\n",
            "Sparsity: 0.9483938320181201\n",
            "Epoch: 43\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7927 - accuracy: 0.6991 - val_loss: 0.7897 - val_accuracy: 0.6954\n",
            "Sparsity: 0.9484832181713617\n",
            "Epoch: 44\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7913 - accuracy: 0.6983 - val_loss: 0.7801 - val_accuracy: 0.6903\n",
            "Sparsity: 0.9485692312622168\n",
            "Epoch: 45\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7895 - accuracy: 0.7028 - val_loss: 0.7967 - val_accuracy: 0.6919\n",
            "Sparsity: 0.9486586174154584\n",
            "Epoch: 46\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7868 - accuracy: 0.7030 - val_loss: 0.7819 - val_accuracy: 0.6998\n",
            "Sparsity: 0.9487513766310864\n",
            "Epoch: 47\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7916 - accuracy: 0.6998 - val_loss: 0.7735 - val_accuracy: 0.7046\n",
            "Sparsity: 0.9488593146274537\n",
            "Epoch: 48\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7818 - accuracy: 0.7026 - val_loss: 0.7751 - val_accuracy: 0.6974\n",
            "Sparsity: 0.948960506499048\n",
            "Epoch: 49\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7815 - accuracy: 0.7049 - val_loss: 0.7683 - val_accuracy: 0.7061\n",
            "Sparsity: 0.9490566387770625\n",
            "Epoch: 50\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7811 - accuracy: 0.7037 - val_loss: 0.7812 - val_accuracy: 0.6966\n",
            "Sparsity: 0.9491392788055312\n",
            "Epoch: 51\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7792 - accuracy: 0.7075 - val_loss: 0.7926 - val_accuracy: 0.6927\n",
            "Sparsity: 0.9492252918963863\n",
            "Epoch: 52\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7747 - accuracy: 0.7077 - val_loss: 0.8385 - val_accuracy: 0.6772\n",
            "Sparsity: 0.9493011858000819\n",
            "Epoch: 53\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7772 - accuracy: 0.7046 - val_loss: 0.7667 - val_accuracy: 0.7069\n",
            "Sparsity: 0.9493669605166183\n",
            "Epoch: 54\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7712 - accuracy: 0.7062 - val_loss: 0.7787 - val_accuracy: 0.7034\n",
            "Sparsity: 0.9494327352331545\n",
            "Epoch: 55\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7738 - accuracy: 0.7049 - val_loss: 0.7708 - val_accuracy: 0.7053\n",
            "Sparsity: 0.9494985099496908\n",
            "Epoch: 56\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7729 - accuracy: 0.7085 - val_loss: 0.7613 - val_accuracy: 0.7109\n",
            "Sparsity: 0.949592955696512\n",
            "Epoch: 57\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7659 - accuracy: 0.7093 - val_loss: 0.7786 - val_accuracy: 0.7042\n",
            "Sparsity: 0.9496469246946957\n",
            "Epoch: 58\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7706 - accuracy: 0.7076 - val_loss: 0.7607 - val_accuracy: 0.7089\n",
            "Sparsity: 0.9497177590048117\n",
            "Epoch: 59\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7645 - accuracy: 0.7105 - val_loss: 0.7970 - val_accuracy: 0.6895\n",
            "Sparsity: 0.9497936529085074\n",
            "Epoch: 60\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7676 - accuracy: 0.7089 - val_loss: 0.7800 - val_accuracy: 0.6978\n",
            "Sparsity: 0.9498661737498166\n",
            "Epoch: 61\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7650 - accuracy: 0.7091 - val_loss: 0.7777 - val_accuracy: 0.7030\n",
            "Sparsity: 0.9499336349975461\n",
            "Epoch: 62\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7701 - accuracy: 0.7077 - val_loss: 0.7741 - val_accuracy: 0.7018\n",
            "Sparsity: 0.9499943501205027\n",
            "Epoch: 63\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7597 - accuracy: 0.7117 - val_loss: 0.7616 - val_accuracy: 0.7042\n",
            "Sparsity: 0.9500786766801645\n",
            "Epoch: 64\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7608 - accuracy: 0.7125 - val_loss: 0.7820 - val_accuracy: 0.6943\n",
            "Sparsity: 0.9501343322095414\n",
            "Epoch: 65\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7689 - accuracy: 0.7083 - val_loss: 0.7476 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9502051665196574\n",
            "Epoch: 66\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7587 - accuracy: 0.7124 - val_loss: 0.7599 - val_accuracy: 0.7089\n",
            "Sparsity: 0.9502827469545463\n",
            "Epoch: 67\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7578 - accuracy: 0.7129 - val_loss: 0.8335 - val_accuracy: 0.6840\n",
            "Sparsity: 0.9503417755463096\n",
            "Epoch: 68\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7571 - accuracy: 0.7114 - val_loss: 0.7714 - val_accuracy: 0.7034\n",
            "Sparsity: 0.9503923714821068\n",
            "Epoch: 69\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7525 - accuracy: 0.7151 - val_loss: 0.7478 - val_accuracy: 0.7141\n",
            "Sparsity: 0.9504480270114836\n",
            "Epoch: 70\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7589 - accuracy: 0.7135 - val_loss: 0.7664 - val_accuracy: 0.7061\n",
            "Sparsity: 0.9505053690720536\n",
            "Epoch: 71\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7532 - accuracy: 0.7180 - val_loss: 0.7455 - val_accuracy: 0.7168\n",
            "Sparsity: 0.9505593380702373\n",
            "Epoch: 72\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7585 - accuracy: 0.7134 - val_loss: 0.7712 - val_accuracy: 0.7022\n",
            "Sparsity: 0.9506234262555803\n",
            "Epoch: 73\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7581 - accuracy: 0.7141 - val_loss: 0.7631 - val_accuracy: 0.7038\n",
            "Sparsity: 0.9506875144409234\n",
            "Epoch: 74\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7513 - accuracy: 0.7170 - val_loss: 0.7733 - val_accuracy: 0.6998\n",
            "Sparsity: 0.950734737314334\n",
            "Epoch: 75\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7509 - accuracy: 0.7152 - val_loss: 0.7994 - val_accuracy: 0.6966\n",
            "Sparsity: 0.9508106312180297\n",
            "Epoch: 76\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7472 - accuracy: 0.7168 - val_loss: 0.7645 - val_accuracy: 0.7053\n",
            "Sparsity: 0.9508612271538268\n",
            "Epoch: 77\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7466 - accuracy: 0.7162 - val_loss: 0.7563 - val_accuracy: 0.7053\n",
            "Sparsity: 0.950911823089624\n",
            "Epoch: 78\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7540 - accuracy: 0.7172 - val_loss: 0.7502 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9509607324942279\n",
            "Epoch: 79\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7499 - accuracy: 0.7158 - val_loss: 0.7469 - val_accuracy: 0.7125\n",
            "Sparsity: 0.9509961496492858\n",
            "Epoch: 80\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7537 - accuracy: 0.7152 - val_loss: 0.7587 - val_accuracy: 0.7156\n",
            "Sparsity: 0.951046745585083\n",
            "Epoch: 81\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7400 - accuracy: 0.7220 - val_loss: 0.7826 - val_accuracy: 0.6990\n",
            "Sparsity: 0.9510990280520734\n",
            "Epoch: 82\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7486 - accuracy: 0.7181 - val_loss: 0.7457 - val_accuracy: 0.7160\n",
            "Sparsity: 0.9511479374566773\n",
            "Epoch: 83\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7498 - accuracy: 0.7169 - val_loss: 0.7435 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9512002199236675\n",
            "Epoch: 84\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7468 - accuracy: 0.7167 - val_loss: 0.7326 - val_accuracy: 0.7255\n",
            "Sparsity: 0.9512440697346918\n",
            "Epoch: 85\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7410 - accuracy: 0.7203 - val_loss: 0.7548 - val_accuracy: 0.7085\n",
            "Sparsity: 0.9512896060769092\n",
            "Epoch: 86\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7462 - accuracy: 0.7156 - val_loss: 0.7599 - val_accuracy: 0.7176\n",
            "Sparsity: 0.9513351424191266\n",
            "Epoch: 87\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7458 - accuracy: 0.7178 - val_loss: 0.7379 - val_accuracy: 0.7196\n",
            "Sparsity: 0.9513840518237305\n",
            "Epoch: 88\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7390 - accuracy: 0.7190 - val_loss: 0.7616 - val_accuracy: 0.7085\n",
            "Sparsity: 0.9514413938843006\n",
            "Epoch: 89\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7405 - accuracy: 0.7200 - val_loss: 0.7737 - val_accuracy: 0.7042\n",
            "Sparsity: 0.951486930226518\n",
            "Epoch: 90\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7425 - accuracy: 0.7215 - val_loss: 0.7546 - val_accuracy: 0.7141\n",
            "Sparsity: 0.9515307800375422\n",
            "Epoch: 91\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7460 - accuracy: 0.7186 - val_loss: 0.7681 - val_accuracy: 0.7006\n",
            "Sparsity: 0.9515796894421461\n",
            "Epoch: 92\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7379 - accuracy: 0.7210 - val_loss: 0.7451 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9516100470036244\n",
            "Epoch: 93\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7379 - accuracy: 0.7213 - val_loss: 0.7440 - val_accuracy: 0.7145\n",
            "Sparsity: 0.951657269877035\n",
            "Epoch: 94\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7373 - accuracy: 0.7216 - val_loss: 0.7628 - val_accuracy: 0.7101\n",
            "Sparsity: 0.9517146119376051\n",
            "Epoch: 95\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7322 - accuracy: 0.7224 - val_loss: 0.7421 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9517652078734022\n",
            "Epoch: 96\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7341 - accuracy: 0.7213 - val_loss: 0.7440 - val_accuracy: 0.7160\n",
            "Sparsity: 0.9518107442156196\n",
            "Epoch: 97\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7351 - accuracy: 0.7229 - val_loss: 0.7685 - val_accuracy: 0.7014\n",
            "Sparsity: 0.9518478479018708\n",
            "Epoch: 98\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7316 - accuracy: 0.7212 - val_loss: 0.7402 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9518916977128951\n",
            "Epoch: 99\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7403 - accuracy: 0.7209 - val_loss: 0.7436 - val_accuracy: 0.7156\n",
            "Sparsity: 0.951933860992726\n",
            "Epoch: 100\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7315 - accuracy: 0.7232 - val_loss: 0.7504 - val_accuracy: 0.7125\n",
            "Sparsity: 0.9519625320230111\n",
            "Epoch: 101\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7369 - accuracy: 0.7200 - val_loss: 0.7380 - val_accuracy: 0.7180\n",
            "Sparsity: 0.9525848620333157\n",
            "Epoch: 102\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7365 - accuracy: 0.7214 - val_loss: 0.7551 - val_accuracy: 0.7141\n",
            "Sparsity: 0.9526911134984897\n",
            "Epoch: 103\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7379 - accuracy: 0.7200 - val_loss: 0.7496 - val_accuracy: 0.7172\n",
            "Sparsity: 0.9527686939333786\n",
            "Epoch: 104\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7340 - accuracy: 0.7237 - val_loss: 0.7635 - val_accuracy: 0.7141\n",
            "Sparsity: 0.9528445878370744\n",
            "Epoch: 105\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7274 - accuracy: 0.7247 - val_loss: 0.7871 - val_accuracy: 0.6998\n",
            "Sparsity: 0.9529221682719633\n",
            "Epoch: 106\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7292 - accuracy: 0.7242 - val_loss: 0.7439 - val_accuracy: 0.7196\n",
            "Sparsity: 0.9529693911453739\n",
            "Epoch: 107\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7300 - accuracy: 0.7230 - val_loss: 0.7350 - val_accuracy: 0.7248\n",
            "Sparsity: 0.9530183005499778\n",
            "Epoch: 108\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7293 - accuracy: 0.7295 - val_loss: 0.7431 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9530773291417411\n",
            "Epoch: 109\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7354 - accuracy: 0.7226 - val_loss: 0.7681 - val_accuracy: 0.7109\n",
            "Sparsity: 0.9531076867032194\n",
            "Epoch: 110\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7275 - accuracy: 0.7244 - val_loss: 0.7445 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9531380442646977\n",
            "Epoch: 111\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7275 - accuracy: 0.7225 - val_loss: 0.7386 - val_accuracy: 0.7164\n",
            "Sparsity: 0.9531835806069151\n",
            "Epoch: 112\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7286 - accuracy: 0.7268 - val_loss: 0.7775 - val_accuracy: 0.7069\n",
            "Sparsity: 0.9532375496050988\n",
            "Epoch: 113\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7253 - accuracy: 0.7242 - val_loss: 0.7308 - val_accuracy: 0.7228\n",
            "Sparsity: 0.9532830859473161\n",
            "Epoch: 114\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7278 - accuracy: 0.7265 - val_loss: 0.7361 - val_accuracy: 0.7196\n",
            "Sparsity: 0.9533201896335673\n",
            "Epoch: 115\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7258 - accuracy: 0.7251 - val_loss: 0.7466 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9533690990381712\n",
            "Epoch: 116\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7209 - accuracy: 0.7266 - val_loss: 0.7699 - val_accuracy: 0.7093\n",
            "Sparsity: 0.9534146353803887\n",
            "Epoch: 117\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7255 - accuracy: 0.7252 - val_loss: 0.7385 - val_accuracy: 0.7248\n",
            "Sparsity: 0.9534719774409588\n",
            "Epoch: 118\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7278 - accuracy: 0.7232 - val_loss: 0.7395 - val_accuracy: 0.7228\n",
            "Sparsity: 0.9535242599079491\n",
            "Epoch: 119\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7212 - accuracy: 0.7264 - val_loss: 0.7467 - val_accuracy: 0.7180\n",
            "Sparsity: 0.9535630501253936\n",
            "Epoch: 120\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7243 - accuracy: 0.7275 - val_loss: 0.7283 - val_accuracy: 0.7279\n",
            "Sparsity: 0.9536102729988043\n",
            "Epoch: 121\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7225 - accuracy: 0.7265 - val_loss: 0.7199 - val_accuracy: 0.7331\n",
            "Sparsity: 0.9536524362786352\n",
            "Epoch: 122\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7173 - accuracy: 0.7285 - val_loss: 0.7458 - val_accuracy: 0.7228\n",
            "Sparsity: 0.9537080918080121\n",
            "Epoch: 123\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7133 - accuracy: 0.7297 - val_loss: 0.7439 - val_accuracy: 0.7208\n",
            "Sparsity: 0.9537367628382971\n",
            "Epoch: 124\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7196 - accuracy: 0.7280 - val_loss: 0.7390 - val_accuracy: 0.7196\n",
            "Sparsity: 0.9537873587740942\n",
            "Epoch: 125\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7184 - accuracy: 0.7281 - val_loss: 0.7384 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9538278355227319\n",
            "Epoch: 126\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7203 - accuracy: 0.7262 - val_loss: 0.7238 - val_accuracy: 0.7323\n",
            "Sparsity: 0.9538716853337561\n",
            "Epoch: 127\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7195 - accuracy: 0.7295 - val_loss: 0.7585 - val_accuracy: 0.7101\n",
            "Sparsity: 0.9539222812695533\n",
            "Epoch: 128\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7147 - accuracy: 0.7301 - val_loss: 0.7343 - val_accuracy: 0.7255\n",
            "Sparsity: 0.9539678176117706\n",
            "Epoch: 129\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7158 - accuracy: 0.7317 - val_loss: 0.7657 - val_accuracy: 0.7117\n",
            "Sparsity: 0.9539880559860895\n",
            "Epoch: 130\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7130 - accuracy: 0.7308 - val_loss: 0.7352 - val_accuracy: 0.7236\n",
            "Sparsity: 0.954020100078761\n",
            "Epoch: 131\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7210 - accuracy: 0.7273 - val_loss: 0.7468 - val_accuracy: 0.7156\n",
            "Sparsity: 0.9540605768273988\n",
            "Epoch: 132\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7120 - accuracy: 0.7323 - val_loss: 0.7518 - val_accuracy: 0.7093\n",
            "Sparsity: 0.954090934388877\n",
            "Epoch: 133\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7175 - accuracy: 0.7273 - val_loss: 0.7488 - val_accuracy: 0.7125\n",
            "Sparsity: 0.9541229784815485\n",
            "Epoch: 134\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7147 - accuracy: 0.7293 - val_loss: 0.7468 - val_accuracy: 0.7113\n",
            "Sparsity: 0.9541634552301862\n",
            "Epoch: 135\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7124 - accuracy: 0.7328 - val_loss: 0.7295 - val_accuracy: 0.7244\n",
            "Sparsity: 0.9541988723852443\n",
            "Epoch: 136\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7102 - accuracy: 0.7362 - val_loss: 0.7436 - val_accuracy: 0.7212\n",
            "Sparsity: 0.9542241703531428\n",
            "Epoch: 137\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7097 - accuracy: 0.7298 - val_loss: 0.7418 - val_accuracy: 0.7200\n",
            "Sparsity: 0.954261274039394\n",
            "Epoch: 138\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7125 - accuracy: 0.7293 - val_loss: 0.7331 - val_accuracy: 0.7196\n",
            "Sparsity: 0.954289945069679\n",
            "Epoch: 139\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7121 - accuracy: 0.7337 - val_loss: 0.7514 - val_accuracy: 0.7176\n",
            "Sparsity: 0.9543253622247371\n",
            "Epoch: 140\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7115 - accuracy: 0.7297 - val_loss: 0.7354 - val_accuracy: 0.7228\n",
            "Sparsity: 0.9543489736614423\n",
            "Epoch: 141\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7136 - accuracy: 0.7276 - val_loss: 0.7339 - val_accuracy: 0.7244\n",
            "Sparsity: 0.9543928234724666\n",
            "Epoch: 142\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7105 - accuracy: 0.7326 - val_loss: 0.7643 - val_accuracy: 0.7141\n",
            "Sparsity: 0.9544198079715583\n",
            "Epoch: 143\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7093 - accuracy: 0.7337 - val_loss: 0.7310 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9544467924706501\n",
            "Epoch: 144\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7100 - accuracy: 0.7294 - val_loss: 0.7537 - val_accuracy: 0.7137\n",
            "Sparsity: 0.9544754635009352\n",
            "Epoch: 145\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7086 - accuracy: 0.7323 - val_loss: 0.7363 - val_accuracy: 0.7244\n",
            "Sparsity: 0.9545041345312202\n",
            "Epoch: 146\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7123 - accuracy: 0.7286 - val_loss: 0.7455 - val_accuracy: 0.7236\n",
            "Sparsity: 0.9545429247486646\n",
            "Epoch: 147\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7087 - accuracy: 0.7327 - val_loss: 0.7225 - val_accuracy: 0.7299\n",
            "Sparsity: 0.9545699092477565\n",
            "Epoch: 148\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7091 - accuracy: 0.7318 - val_loss: 0.7477 - val_accuracy: 0.7164\n",
            "Sparsity: 0.9545901476220754\n",
            "Epoch: 149\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7102 - accuracy: 0.7294 - val_loss: 0.7303 - val_accuracy: 0.7283\n",
            "Sparsity: 0.9546171321211672\n",
            "Epoch: 150\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7057 - accuracy: 0.7335 - val_loss: 0.7288 - val_accuracy: 0.7299\n",
            "Sparsity: 0.9546390570266793\n",
            "Epoch: 151\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7101 - accuracy: 0.7330 - val_loss: 0.7526 - val_accuracy: 0.7200\n",
            "Sparsity: 0.9609449971581949\n",
            "Epoch: 152\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7824 - accuracy: 0.7006 - val_loss: 0.7373 - val_accuracy: 0.7208\n",
            "Sparsity: 0.9610832927160404\n",
            "Epoch: 153\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7676 - accuracy: 0.7111 - val_loss: 0.7580 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9611895441812144\n",
            "Epoch: 154\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7547 - accuracy: 0.7164 - val_loss: 0.7387 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9612704976784898\n",
            "Epoch: 155\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7559 - accuracy: 0.7099 - val_loss: 0.7562 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9613514511757653\n",
            "Epoch: 156\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7432 - accuracy: 0.7215 - val_loss: 0.7594 - val_accuracy: 0.7105\n",
            "Sparsity: 0.9614307181418474\n",
            "Epoch: 157\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7441 - accuracy: 0.7154 - val_loss: 0.7461 - val_accuracy: 0.7212\n",
            "Sparsity: 0.9615167312327025\n",
            "Epoch: 158\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7422 - accuracy: 0.7183 - val_loss: 0.7338 - val_accuracy: 0.7251\n",
            "Sparsity: 0.9615504618565672\n",
            "Epoch: 159\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7423 - accuracy: 0.7182 - val_loss: 0.7401 - val_accuracy: 0.7129\n",
            "Sparsity: 0.9616010577923644\n",
            "Epoch: 160\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7359 - accuracy: 0.7189 - val_loss: 0.7335 - val_accuracy: 0.7168\n",
            "Sparsity: 0.9616398480098088\n",
            "Epoch: 161\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7374 - accuracy: 0.7225 - val_loss: 0.7315 - val_accuracy: 0.7244\n",
            "Sparsity: 0.9616803247584466\n",
            "Epoch: 162\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7395 - accuracy: 0.7177 - val_loss: 0.7297 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9617241745694708\n",
            "Epoch: 163\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7314 - accuracy: 0.7247 - val_loss: 0.7678 - val_accuracy: 0.7109\n",
            "Sparsity: 0.9617713974428814\n",
            "Epoch: 164\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7317 - accuracy: 0.7196 - val_loss: 0.7224 - val_accuracy: 0.7287\n",
            "Sparsity: 0.9618236799098717\n",
            "Epoch: 165\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7373 - accuracy: 0.7200 - val_loss: 0.7507 - val_accuracy: 0.7129\n",
            "Sparsity: 0.9618742758456689\n",
            "Epoch: 166\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7338 - accuracy: 0.7208 - val_loss: 0.7382 - val_accuracy: 0.7121\n",
            "Sparsity: 0.9619214987190795\n",
            "Epoch: 167\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7315 - accuracy: 0.7213 - val_loss: 0.7279 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9619653485301037\n",
            "Epoch: 168\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7281 - accuracy: 0.7248 - val_loss: 0.7417 - val_accuracy: 0.7129\n",
            "Sparsity: 0.9620075118099347\n",
            "Epoch: 169\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7325 - accuracy: 0.7215 - val_loss: 0.7738 - val_accuracy: 0.7006\n",
            "Sparsity: 0.9620429289649927\n",
            "Epoch: 170\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7239 - accuracy: 0.7248 - val_loss: 0.7556 - val_accuracy: 0.7089\n",
            "Sparsity: 0.9620766595888575\n",
            "Epoch: 171\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7248 - accuracy: 0.7216 - val_loss: 0.7309 - val_accuracy: 0.7263\n",
            "Sparsity: 0.9621188228686883\n",
            "Epoch: 172\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7270 - accuracy: 0.7265 - val_loss: 0.7369 - val_accuracy: 0.7220\n",
            "Sparsity: 0.9621491804301666\n",
            "Epoch: 173\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7289 - accuracy: 0.7223 - val_loss: 0.7464 - val_accuracy: 0.7109\n",
            "Sparsity: 0.9621761649292585\n",
            "Epoch: 174\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7234 - accuracy: 0.7231 - val_loss: 0.7145 - val_accuracy: 0.7251\n",
            "Sparsity: 0.962214955146703\n",
            "Epoch: 175\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7331 - accuracy: 0.7230 - val_loss: 0.7399 - val_accuracy: 0.7172\n",
            "Sparsity: 0.9622520588329542\n",
            "Epoch: 176\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7260 - accuracy: 0.7245 - val_loss: 0.7226 - val_accuracy: 0.7263\n",
            "Sparsity: 0.9622773568008527\n",
            "Epoch: 177\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7278 - accuracy: 0.7240 - val_loss: 0.7505 - val_accuracy: 0.7109\n",
            "Sparsity: 0.9623060278311377\n",
            "Epoch: 178\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7234 - accuracy: 0.7245 - val_loss: 0.7389 - val_accuracy: 0.7204\n",
            "Sparsity: 0.9623380719238093\n",
            "Epoch: 179\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7228 - accuracy: 0.7246 - val_loss: 0.7221 - val_accuracy: 0.7172\n",
            "Sparsity: 0.9623532507045484\n",
            "Epoch: 180\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7180 - accuracy: 0.7296 - val_loss: 0.7327 - val_accuracy: 0.7172\n",
            "Sparsity: 0.962378548672447\n",
            "Epoch: 181\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7257 - accuracy: 0.7273 - val_loss: 0.7582 - val_accuracy: 0.7192\n",
            "Sparsity: 0.9624105927651185\n",
            "Epoch: 182\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7240 - accuracy: 0.7265 - val_loss: 0.7158 - val_accuracy: 0.7319\n",
            "Sparsity: 0.96244263685779\n",
            "Epoch: 183\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7225 - accuracy: 0.7255 - val_loss: 0.7255 - val_accuracy: 0.7283\n",
            "Sparsity: 0.9624561291073359\n",
            "Epoch: 184\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7192 - accuracy: 0.7254 - val_loss: 0.7397 - val_accuracy: 0.7164\n",
            "Sparsity: 0.9624915462623939\n",
            "Epoch: 185\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7186 - accuracy: 0.7251 - val_loss: 0.7410 - val_accuracy: 0.7149\n",
            "Sparsity: 0.9625219038238721\n",
            "Epoch: 186\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7189 - accuracy: 0.7281 - val_loss: 0.7413 - val_accuracy: 0.7196\n",
            "Sparsity: 0.9625590075101234\n",
            "Epoch: 187\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7182 - accuracy: 0.7286 - val_loss: 0.7388 - val_accuracy: 0.7176\n",
            "Sparsity: 0.962584305478022\n",
            "Epoch: 188\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7180 - accuracy: 0.7263 - val_loss: 0.7303 - val_accuracy: 0.7216\n",
            "Sparsity: 0.9626146630395003\n",
            "Epoch: 189\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7159 - accuracy: 0.7310 - val_loss: 0.7239 - val_accuracy: 0.7224\n",
            "Sparsity: 0.962648393663365\n",
            "Epoch: 190\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7190 - accuracy: 0.7277 - val_loss: 0.7335 - val_accuracy: 0.7228\n",
            "Sparsity: 0.9626753781624569\n",
            "Epoch: 191\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7185 - accuracy: 0.7271 - val_loss: 0.7610 - val_accuracy: 0.7101\n",
            "Sparsity: 0.9627091087863215\n",
            "Epoch: 192\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7166 - accuracy: 0.7303 - val_loss: 0.7385 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9627360932854133\n",
            "Epoch: 193\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7124 - accuracy: 0.7293 - val_loss: 0.7400 - val_accuracy: 0.7291\n",
            "Sparsity: 0.9627495855349593\n",
            "Epoch: 194\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7160 - accuracy: 0.7293 - val_loss: 0.7348 - val_accuracy: 0.7204\n",
            "Sparsity: 0.9627731969716646\n",
            "Epoch: 195\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7135 - accuracy: 0.7309 - val_loss: 0.7425 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9628103006579158\n",
            "Epoch: 196\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7124 - accuracy: 0.7304 - val_loss: 0.7242 - val_accuracy: 0.7251\n",
            "Sparsity: 0.9628305390322347\n",
            "Epoch: 197\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7163 - accuracy: 0.7313 - val_loss: 0.7602 - val_accuracy: 0.7069\n",
            "Sparsity: 0.9628490908753603\n",
            "Epoch: 198\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7187 - accuracy: 0.7269 - val_loss: 0.7117 - val_accuracy: 0.7335\n",
            "Sparsity: 0.9628794484368386\n",
            "Epoch: 199\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7111 - accuracy: 0.7318 - val_loss: 0.7250 - val_accuracy: 0.7224\n",
            "Sparsity: 0.9629098059983169\n",
            "Epoch: 200\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7143 - accuracy: 0.7291 - val_loss: 0.7159 - val_accuracy: 0.7339\n",
            "Sparsity: 0.9629283578414425\n",
            "Epoch: 201\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7149 - accuracy: 0.7286 - val_loss: 0.7556 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9659354429589853\n",
            "Epoch: 202\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7928 - accuracy: 0.7011 - val_loss: 0.7696 - val_accuracy: 0.7141\n",
            "Sparsity: 0.9660282021746133\n",
            "Epoch: 203\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7828 - accuracy: 0.7027 - val_loss: 0.7536 - val_accuracy: 0.7117\n",
            "Sparsity: 0.9661344536397873\n",
            "Epoch: 204\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7765 - accuracy: 0.7053 - val_loss: 0.7591 - val_accuracy: 0.7101\n",
            "Sparsity: 0.9662120340746763\n",
            "Epoch: 205\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7651 - accuracy: 0.7127 - val_loss: 0.7476 - val_accuracy: 0.7176\n",
            "Sparsity: 0.9662778087912125\n",
            "Epoch: 206\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7558 - accuracy: 0.7167 - val_loss: 0.7459 - val_accuracy: 0.7137\n",
            "Sparsity: 0.9663553892261014\n",
            "Epoch: 207\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7576 - accuracy: 0.7160 - val_loss: 0.7493 - val_accuracy: 0.7149\n",
            "Sparsity: 0.9664026120995121\n",
            "Epoch: 208\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7525 - accuracy: 0.7192 - val_loss: 0.7582 - val_accuracy: 0.7129\n",
            "Sparsity: 0.9664498349729227\n",
            "Epoch: 209\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7592 - accuracy: 0.7132 - val_loss: 0.7464 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9665004309087198\n",
            "Epoch: 210\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7542 - accuracy: 0.7125 - val_loss: 0.7487 - val_accuracy: 0.7113\n",
            "Sparsity: 0.9665459672509373\n",
            "Epoch: 211\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7541 - accuracy: 0.7172 - val_loss: 0.7490 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9666049958427007\n",
            "Epoch: 212\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7508 - accuracy: 0.7186 - val_loss: 0.7432 - val_accuracy: 0.7160\n",
            "Sparsity: 0.9666471591225315\n",
            "Epoch: 213\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7506 - accuracy: 0.7165 - val_loss: 0.7676 - val_accuracy: 0.7069\n",
            "Sparsity: 0.9666910089335558\n",
            "Epoch: 214\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7500 - accuracy: 0.7176 - val_loss: 0.7530 - val_accuracy: 0.7137\n",
            "Sparsity: 0.9667297991510002\n",
            "Epoch: 215\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7502 - accuracy: 0.7177 - val_loss: 0.7378 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9667618432436718\n",
            "Epoch: 216\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7475 - accuracy: 0.7175 - val_loss: 0.7803 - val_accuracy: 0.7006\n",
            "Sparsity: 0.9667972603987297\n",
            "Epoch: 217\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7446 - accuracy: 0.7189 - val_loss: 0.7539 - val_accuracy: 0.7180\n",
            "Sparsity: 0.9668495428657201\n",
            "Epoch: 218\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7381 - accuracy: 0.7228 - val_loss: 0.7485 - val_accuracy: 0.7145\n",
            "Sparsity: 0.9669085714574834\n",
            "Epoch: 219\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7409 - accuracy: 0.7203 - val_loss: 0.7685 - val_accuracy: 0.7077\n",
            "Sparsity: 0.9669355559565752\n",
            "Epoch: 220\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7409 - accuracy: 0.7180 - val_loss: 0.7545 - val_accuracy: 0.7141\n",
            "Sparsity: 0.9669861518923724\n",
            "Epoch: 221\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7415 - accuracy: 0.7183 - val_loss: 0.7405 - val_accuracy: 0.7192\n",
            "Sparsity: 0.9670232555786236\n",
            "Epoch: 222\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7430 - accuracy: 0.7217 - val_loss: 0.7573 - val_accuracy: 0.7156\n",
            "Sparsity: 0.9670654188584545\n",
            "Epoch: 223\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7424 - accuracy: 0.7197 - val_loss: 0.7452 - val_accuracy: 0.7200\n",
            "Sparsity: 0.9670890302951598\n",
            "Epoch: 224\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7369 - accuracy: 0.7213 - val_loss: 0.7548 - val_accuracy: 0.7121\n",
            "Sparsity: 0.9671143282630584\n",
            "Epoch: 225\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7379 - accuracy: 0.7210 - val_loss: 0.7484 - val_accuracy: 0.7204\n",
            "Sparsity: 0.9671413127621502\n",
            "Epoch: 226\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7373 - accuracy: 0.7216 - val_loss: 0.7378 - val_accuracy: 0.7216\n",
            "Sparsity: 0.9671733568548218\n",
            "Epoch: 227\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7437 - accuracy: 0.7194 - val_loss: 0.7290 - val_accuracy: 0.7248\n",
            "Sparsity: 0.9671986548227203\n",
            "Epoch: 228\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7392 - accuracy: 0.7214 - val_loss: 0.7283 - val_accuracy: 0.7196\n",
            "Sparsity: 0.967225639321812\n",
            "Epoch: 229\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7386 - accuracy: 0.7191 - val_loss: 0.7405 - val_accuracy: 0.7251\n",
            "Sparsity: 0.9672475642273242\n",
            "Epoch: 230\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7378 - accuracy: 0.7227 - val_loss: 0.7554 - val_accuracy: 0.7109\n",
            "Sparsity: 0.967281294851189\n",
            "Epoch: 231\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7397 - accuracy: 0.7211 - val_loss: 0.7544 - val_accuracy: 0.7176\n",
            "Sparsity: 0.9673116524126671\n",
            "Epoch: 232\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7396 - accuracy: 0.7228 - val_loss: 0.7564 - val_accuracy: 0.7149\n",
            "Sparsity: 0.9673335773181793\n",
            "Epoch: 233\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7373 - accuracy: 0.7220 - val_loss: 0.7521 - val_accuracy: 0.7125\n",
            "Sparsity: 0.9673588752860779\n",
            "Epoch: 234\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7451 - accuracy: 0.7182 - val_loss: 0.7243 - val_accuracy: 0.7299\n",
            "Sparsity: 0.9673791136603967\n",
            "Epoch: 235\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7342 - accuracy: 0.7243 - val_loss: 0.7273 - val_accuracy: 0.7236\n",
            "Sparsity: 0.9674060981594885\n",
            "Epoch: 236\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7360 - accuracy: 0.7210 - val_loss: 0.7521 - val_accuracy: 0.7172\n",
            "Sparsity: 0.9674330826585803\n",
            "Epoch: 237\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7375 - accuracy: 0.7222 - val_loss: 0.7346 - val_accuracy: 0.7259\n",
            "Sparsity: 0.9674499479705126\n",
            "Epoch: 238\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7327 - accuracy: 0.7225 - val_loss: 0.7665 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9674718728760248\n",
            "Epoch: 239\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7350 - accuracy: 0.7203 - val_loss: 0.7368 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9674853651255707\n",
            "Epoch: 240\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7347 - accuracy: 0.7237 - val_loss: 0.7327 - val_accuracy: 0.7267\n",
            "Sparsity: 0.9675005439063098\n",
            "Epoch: 241\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7318 - accuracy: 0.7241 - val_loss: 0.7767 - val_accuracy: 0.7053\n",
            "Sparsity: 0.9675342745301746\n",
            "Epoch: 242\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7366 - accuracy: 0.7230 - val_loss: 0.7351 - val_accuracy: 0.7236\n",
            "Sparsity: 0.9675528263733002\n",
            "Epoch: 243\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7325 - accuracy: 0.7256 - val_loss: 0.7415 - val_accuracy: 0.7224\n",
            "Sparsity: 0.9675747512788123\n",
            "Epoch: 244\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7305 - accuracy: 0.7216 - val_loss: 0.7435 - val_accuracy: 0.7204\n",
            "Sparsity: 0.9675983627155176\n",
            "Epoch: 245\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7344 - accuracy: 0.7239 - val_loss: 0.7341 - val_accuracy: 0.7295\n",
            "Sparsity: 0.9676169145586432\n",
            "Epoch: 246\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7339 - accuracy: 0.7225 - val_loss: 0.7524 - val_accuracy: 0.7216\n",
            "Sparsity: 0.9676337798705756\n",
            "Epoch: 247\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7300 - accuracy: 0.7245 - val_loss: 0.7536 - val_accuracy: 0.7133\n",
            "Sparsity: 0.9676523317137012\n",
            "Epoch: 248\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7276 - accuracy: 0.7236 - val_loss: 0.7589 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9676725700880201\n",
            "Epoch: 249\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7291 - accuracy: 0.7226 - val_loss: 0.7482 - val_accuracy: 0.7184\n",
            "Sparsity: 0.9676978680559186\n",
            "Epoch: 250\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7280 - accuracy: 0.7238 - val_loss: 0.7540 - val_accuracy: 0.7145\n",
            "Sparsity: 0.9677113603054646\n",
            "Epoch: 251\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7316 - accuracy: 0.7233 - val_loss: 0.7277 - val_accuracy: 0.7212\n",
            "Sparsity: 0.9677315986797834\n",
            "Epoch: 252\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7351 - accuracy: 0.7230 - val_loss: 0.7512 - val_accuracy: 0.7172\n",
            "Sparsity: 0.967750150522909\n",
            "Epoch: 253\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7282 - accuracy: 0.7246 - val_loss: 0.8360 - val_accuracy: 0.6828\n",
            "Sparsity: 0.9677636427724549\n",
            "Epoch: 254\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7327 - accuracy: 0.7274 - val_loss: 0.7371 - val_accuracy: 0.7208\n",
            "Sparsity: 0.9677771350220008\n",
            "Epoch: 255\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7273 - accuracy: 0.7218 - val_loss: 0.7333 - val_accuracy: 0.7251\n",
            "Sparsity: 0.9677956868651264\n",
            "Epoch: 256\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7333 - accuracy: 0.7227 - val_loss: 0.7318 - val_accuracy: 0.7244\n",
            "Sparsity: 0.967814238708252\n",
            "Epoch: 257\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7285 - accuracy: 0.7244 - val_loss: 0.7302 - val_accuracy: 0.7208\n",
            "Sparsity: 0.9678344770825709\n",
            "Epoch: 258\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7279 - accuracy: 0.7257 - val_loss: 0.7375 - val_accuracy: 0.7204\n",
            "Sparsity: 0.9678496558633101\n",
            "Epoch: 259\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7327 - accuracy: 0.7213 - val_loss: 0.7435 - val_accuracy: 0.7196\n",
            "Sparsity: 0.9678749538312086\n",
            "Epoch: 260\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7268 - accuracy: 0.7237 - val_loss: 0.7659 - val_accuracy: 0.7061\n",
            "Sparsity: 0.9678833864871748\n",
            "Epoch: 261\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7234 - accuracy: 0.7251 - val_loss: 0.7492 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9678901326119477\n",
            "Epoch: 262\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7277 - accuracy: 0.7239 - val_loss: 0.7414 - val_accuracy: 0.7196\n",
            "Sparsity: 0.9679036248614936\n",
            "Epoch: 263\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7231 - accuracy: 0.7283 - val_loss: 0.7458 - val_accuracy: 0.7133\n",
            "Sparsity: 0.9679289228293922\n",
            "Epoch: 264\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7279 - accuracy: 0.7269 - val_loss: 0.7533 - val_accuracy: 0.7188\n",
            "Sparsity: 0.9679542207972908\n",
            "Epoch: 265\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7249 - accuracy: 0.7254 - val_loss: 0.7466 - val_accuracy: 0.7204\n",
            "Sparsity: 0.9679744591716096\n",
            "Epoch: 266\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7298 - accuracy: 0.7244 - val_loss: 0.7267 - val_accuracy: 0.7248\n",
            "Sparsity: 0.9679930110147352\n",
            "Epoch: 267\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7268 - accuracy: 0.7257 - val_loss: 0.7371 - val_accuracy: 0.7240\n",
            "Sparsity: 0.9680132493890541\n",
            "Epoch: 268\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7288 - accuracy: 0.7248 - val_loss: 0.7510 - val_accuracy: 0.7145\n",
            "Sparsity: 0.9680267416386\n",
            "Epoch: 269\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7211 - accuracy: 0.7284 - val_loss: 0.7647 - val_accuracy: 0.7089\n",
            "Sparsity: 0.9680436069505324\n",
            "Epoch: 270\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7284 - accuracy: 0.7265 - val_loss: 0.7571 - val_accuracy: 0.7121\n",
            "Sparsity: 0.9680655318560445\n",
            "Epoch: 271\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7223 - accuracy: 0.7285 - val_loss: 0.7481 - val_accuracy: 0.7184\n",
            "Sparsity: 0.9680857702303632\n",
            "Epoch: 272\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7240 - accuracy: 0.7279 - val_loss: 0.7563 - val_accuracy: 0.7125\n",
            "Sparsity: 0.9681076951358754\n",
            "Epoch: 273\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7227 - accuracy: 0.7285 - val_loss: 0.7425 - val_accuracy: 0.7152\n",
            "Sparsity: 0.9681380526973536\n",
            "Epoch: 274\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7207 - accuracy: 0.7300 - val_loss: 0.7237 - val_accuracy: 0.7271\n",
            "Sparsity: 0.9681481718845131\n",
            "Epoch: 275\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7206 - accuracy: 0.7259 - val_loss: 0.7487 - val_accuracy: 0.7156\n",
            "Sparsity: 0.9681734698524117\n",
            "Epoch: 276\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7264 - accuracy: 0.7276 - val_loss: 0.7337 - val_accuracy: 0.7220\n",
            "Sparsity: 0.9681869621019575\n",
            "Epoch: 277\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7187 - accuracy: 0.7293 - val_loss: 0.7354 - val_accuracy: 0.7200\n",
            "Sparsity: 0.968190335164344\n",
            "Epoch: 278\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7227 - accuracy: 0.7288 - val_loss: 0.7256 - val_accuracy: 0.7335\n",
            "Sparsity: 0.9682038274138899\n",
            "Epoch: 279\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7235 - accuracy: 0.7264 - val_loss: 0.7295 - val_accuracy: 0.7232\n",
            "Sparsity: 0.9682240657882087\n",
            "Epoch: 280\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7188 - accuracy: 0.7268 - val_loss: 0.7205 - val_accuracy: 0.7299\n",
            "Sparsity: 0.968232498444175\n",
            "Epoch: 281\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7184 - accuracy: 0.7291 - val_loss: 0.7451 - val_accuracy: 0.7164\n",
            "Sparsity: 0.9682476772249141\n",
            "Epoch: 282\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7197 - accuracy: 0.7261 - val_loss: 0.7213 - val_accuracy: 0.7271\n",
            "Sparsity: 0.9682594829432668\n",
            "Epoch: 283\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7229 - accuracy: 0.7275 - val_loss: 0.7197 - val_accuracy: 0.7311\n",
            "Sparsity: 0.9682763482551991\n",
            "Epoch: 284\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7138 - accuracy: 0.7303 - val_loss: 0.7282 - val_accuracy: 0.7216\n",
            "Sparsity: 0.9682847809111653\n",
            "Epoch: 285\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7196 - accuracy: 0.7263 - val_loss: 0.7471 - val_accuracy: 0.7224\n",
            "Sparsity: 0.9682932135671315\n",
            "Epoch: 286\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7260 - accuracy: 0.7244 - val_loss: 0.7489 - val_accuracy: 0.7121\n",
            "Sparsity: 0.9683016462230977\n",
            "Epoch: 287\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7171 - accuracy: 0.7281 - val_loss: 0.7370 - val_accuracy: 0.7303\n",
            "Sparsity: 0.9683201980662234\n",
            "Epoch: 288\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7174 - accuracy: 0.7303 - val_loss: 0.7371 - val_accuracy: 0.7236\n",
            "Sparsity: 0.9683404364405422\n",
            "Epoch: 289\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7164 - accuracy: 0.7289 - val_loss: 0.7478 - val_accuracy: 0.7188\n",
            "Sparsity: 0.968360674814861\n",
            "Epoch: 290\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7208 - accuracy: 0.7305 - val_loss: 0.7209 - val_accuracy: 0.7287\n",
            "Sparsity: 0.9683792266579867\n",
            "Epoch: 291\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7154 - accuracy: 0.7306 - val_loss: 0.7307 - val_accuracy: 0.7212\n",
            "Sparsity: 0.9683876593139529\n",
            "Epoch: 292\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7209 - accuracy: 0.7274 - val_loss: 0.7336 - val_accuracy: 0.7263\n",
            "Sparsity: 0.9684045246258852\n",
            "Epoch: 293\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7181 - accuracy: 0.7325 - val_loss: 0.7499 - val_accuracy: 0.7145\n",
            "Sparsity: 0.9684163303442379\n",
            "Epoch: 294\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7211 - accuracy: 0.7274 - val_loss: 0.7353 - val_accuracy: 0.7236\n",
            "Sparsity: 0.968431509124977\n",
            "Epoch: 295\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7226 - accuracy: 0.7271 - val_loss: 0.7610 - val_accuracy: 0.7085\n",
            "Sparsity: 0.9684416283121364\n",
            "Epoch: 296\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7166 - accuracy: 0.7282 - val_loss: 0.7167 - val_accuracy: 0.7347\n",
            "Sparsity: 0.9684534340304891\n",
            "Epoch: 297\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7160 - accuracy: 0.7301 - val_loss: 0.7214 - val_accuracy: 0.7287\n",
            "Sparsity: 0.9684702993424215\n",
            "Epoch: 298\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7189 - accuracy: 0.7282 - val_loss: 0.7717 - val_accuracy: 0.7105\n",
            "Sparsity: 0.9684854781231607\n",
            "Epoch: 299\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7180 - accuracy: 0.7304 - val_loss: 0.7461 - val_accuracy: 0.7192\n",
            "Sparsity: 0.968502343435093\n",
            "Epoch: 300\n",
            "1405/1405 [==============================] - 6s 4ms/step - loss: 0.7137 - accuracy: 0.7319 - val_loss: 0.7426 - val_accuracy: 0.7220\n",
            "Sparsity: 0.968515835684639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prune_weights = model.get_weights()\n",
        "prune_test_weights = np.array(prune_weights)\n",
        "sparse = []\n",
        "new_zero_wts, new_total_params = 0, 0\n",
        "for val in range (12):\n",
        "  z, t, sparsity_val = sparsity(prune_test_weights[val])\n",
        "  new_zero_wts += z\n",
        "  new_total_params += t\n",
        "  sparse.append(sparsity_val)\n",
        "\n",
        "final_sparsity = 0\n",
        "for arr in model.trainable_variables:\n",
        "    final_sparsity += len(tf.where(arr==0.0))\n",
        "print(\"Sparsity: {}\".format( final_sparsity/592933))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gehBCXc6RDRH",
        "outputId": "d462f7fc-8ff7-47b9-eaed-d66babe465a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity: 0.968515835684639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-116-af0ce0c3c1e2>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  prune_test_weights = np.array(prune_weights)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhpP7M24T9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a37f9b-76f8-4ce8-e367-d3e09c2c0f0b"
      },
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7411 - accuracy: 0.7224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = (results[1] + new_zero_wts / new_total_params) / 2\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJt_YPYNRJC2",
        "outputId": "c0bc714d-a967-42d4-d588-c22b5290fa20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8428717665285377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sparsity_val = (sum(sparse))/(len(sparse))\n",
        "# accuracy_val = results[1]\n",
        "# sparsity_list.append(sparsity_val)\n",
        "# accuracy_list.append(accuracy_val)\n",
        "# print(sparsity_list)\n",
        "# print(accuracy_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2N2XvP1Arg-",
        "outputId": "42ad70d6-2711-4c19-8f1c-0c4847b5621e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7958669427000448, 0.8036446983431592, 0.8157233202898944, 0.8237027238916467, 0.8324106863987297, 0.8405716213179225, 0.8474994070735976, 0.8537342648447295, 0.8624042616950139, 0.8701754499364781, 0.8950132876266669]\n",
            "[0.742178201675415, 0.7342574000358582, 0.7390099167823792, 0.7326732873916626, 0.7370297312736511, 0.7283168435096741, 0.7287128567695618, 0.7192079424858093, 0.7112871408462524, 0.7128713130950928, 0.7100989818572998]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# sparsity_dict = {'Sparsity': sparsity_list}\n",
        "# accuracy_dict = {'Accuracy': accuracy_list}\n",
        "\n",
        "# sparsity_df = pd.DataFrame(sparsity_dict)\n",
        "# accuracy_df = pd.DataFrame(accuracy_dict)\n",
        "\n",
        "# sparsity_df.to_csv('Magnitude_Pruning_Sparsity.csv')\n",
        "# accuracy_df.to_csv('Magnitude_Pruning_Accuracy.csv')"
      ],
      "metadata": {
        "id": "FT6Bk_jwMYdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model.save_weights(\"my_model_weights.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sz-TveyGdehI",
        "outputId": "4c670291-95c5-4cbb-804a-60d70669b6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d32e505a-8a72-49bf-8edc-7ebdc4e79fbb\", \"my_model_weights.h5\", 2407560)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Attempt\n",
        "## Score: 0.53"
      ],
      "metadata": {
        "id": "ZnyEelZFRKAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_weights = np.array(original_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaLDZdy_n4sC",
        "outputId": "2550e9ed-19b0-44f9-f029-c943a986619d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjw94aij4T-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd072d6-e313-4951-953b-81d985c58846"
      },
      "source": [
        "# perform pruning here\n",
        "mask = []\n",
        "sparse = []\n",
        "zero_wts, total_params = 0, 0\n",
        "for val in range (12):\n",
        "  baseline_weights[val][np.where(np.abs(baseline_weights[val]) < 0.0253)] = 0.0\n",
        "  wts = baseline_weights[val]\n",
        "  z, t, sparsity_val = sparsity(wts)\n",
        "  zero_wts += z\n",
        "  total_params += t\n",
        "  sparse.append(sparsity_val)\n",
        "\n",
        "final_sparsity = 0\n",
        "for arr in model.trainable_variables:\n",
        "    final_sparsity += len(tf.where(arr==0.0))\n",
        "print(\"Sparsity: {}\".format( final_sparsity/592933))\n",
        "\n",
        "# you can use set_weights() to set some weights to zero, e.g.,\n",
        "# some references for pruning techniques: https://arxiv.org/pdf/1810.05270v2.pdf, https://arxiv.org/pdf/2001.04062.pdf\n",
        "\n",
        "model.set_weights(baseline_weights)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity is: 0.48413984392896103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUuNXFjV4T-E",
        "outputId": "ec6e5b04-703c-4304-a21a-cff0f8fa813e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8446 - accuracy: 0.6792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = (0.6792 + zero_wts / total_params) / 2\n",
        "print(score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8WLu7hm_Fx0",
        "outputId": "8e19f511-5437-4c0b-bb24-ec3091198abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5308340854700279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSKQW4k4T-G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ed6a2dd5-dc7a-4e9a-af77-b6e302ba2878"
      },
      "source": [
        "# # you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model.save_weights(\"my_model_weights.h5\")\n",
        "\n",
        "# # running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d300b53-dd77-467d-a85f-aec91052cb73\", \"my_model_weights.h5\", 2407560)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}